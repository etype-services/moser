# Node Revision Cleanup

## Introduction

This module is not intended for novice users or the Drupal layman. This module, currently, has no GUI interface. The primary reason is because we don't want the overhead of running Apache on top of the already difficult work this module does. If it weren't for Drupal's [node_revision_delete](https://api.drupal.org/api/drupal/modules%21node%21node.module/function/node_revision_delete/7) function spawning all the necessary field deletion functions, this script would probably just be a random PHP utility script you found on some random dude's github account.

At this point, I would like to reiterate, this module is not for you if you only have a few stray revisions laying around. There are other modules for managing smaller numbers of revision deletions. Those modules are [Node Revision Delete](https://www.drupal.org/project/node_revision_delete) and [Node Revision Restrict](https://www.drupal.org/project/node_revision_restrict). However, if you have more than 500,000 rows in your node_revision table, this _may_ be the route for you.

This module is pretty straightforward: build a list of node revisions for a given content type, break that into manageable chunks (called jobs), work on each job sequentially until all of the revisions are cleaned up.

## What's all this markup cruft?

You thought this was just a plain ol' text file, didn't you? Technically, you're correct. I've made use of a minimally invasive markup language called [Markdown](http://daringfireball.net/projects/markdown/syntax). Grab a markdown editor and format the file. [Mou](http://mouapp.com) is an awesome choice for Mac. I don't use Windows, but the first result on Google seems to have similar features to Mou, so, here's the link for [MarkdownPad](http://markdownpad.com). It is infrequent that I find myself using Linux in GUI mode, so I'm going to have to suggest [makeuseof's list](http://www.makeuseof.com/tag/looking-markdown-editor-linux-try-3-solid-options/).

## Optional Installations

You may, at your discretion, though it is highly recommended, install and configure a Memcache server and either of the PECL modules for your site. If you already have, kudos. The instructions for doing so are located out there on the web somewhere. Once you've done that, install and enable the [Memcache module](https://www.drupal.org/project/memcache).

If the Memcache module is installed for your site, the module will automatically use Memcache to store its job queue. I, personally, have noticed about a 200% bump in speed using memcache with this process, so...yeah.

## Installation
Install and enable as any other Drupal 7 module. Be a lamb, use drush.

## Usage

Don't use this on a live production site. Don't. Take proper precautions. Make backups. Use an offline version of the site to run the process and then replace the live database at a convenient-for-your-users time.

There. I said it. Are you happy?

### Step zero - Back that junk up.

No, but seriously, back up your database. Right now. Don't know how? Open a terminal window. CD to your Drupal root. Type `drush sql-dump --result-file=/path/to/backup.sql`. You knew how. Stop being lazy.

### Step one - Generate the jobs.

Again, be an awesome lamb and open your terminal window. Or five. Really, though, you probably only need two. In the first window, change or ssh (have you tried [mosh](http://mosh.mit.edu)?) to your Drupal site's root directory. Run

	drush nrc-gq %content-type% --revisions=%revisions-to-keep%

OR

	drush nrc-gq %content-type% --tp=%time-phrase%


where `%content-type%` is the machine name of the content type for which you wish to delete revisions. Either provide the option `--revisions` with `%revisions-to-keep%`, which is the number of revisions you wish to maintain per node of that content type, or the option `--tp` with `%time-phrase%` being a string that PHP's [date_modify()](http://php.net/manual/en/function.date-modify.php) can understand like `-30 days` or `-1 year`. All of the node revisions _older than_ the specified `%time-phrase%` will be kept. The `%time-phrase%` is relative to the time the script is initiated.

**WARNING:** It is entirely intentional that you are able to pass positive values as a `%time-phrase%`. The next step "work lists" will, in most cases, __DELETE ALL REVISIONS__ except the current if a `%time-phrase%` such as `+1 week` is passed into the generate queue function AND THEN the work list function is run. This is why they're separate - to give you time to recover from a boo-boo. To recover from this particular boo-boo, re-run nrc-gq with the right phrase to overwrite the work lists.

This process will take between 5 seconds and 38 years, depending on how tricked out your system is. Upon completion, you'll see a message along the lines of:

	63 jobs available with a total of 62602 revisions to delete.

This message means you're good to go for step two.

### Step two - Work all the jobs!

[Yes, I'll wait.](http://memegenerator.net/X-All-The-Y)
You're back? K. Now, in the same terminal window where you just generated the jobs, type `drush nrc-wl %content-type% %group-number% &`, using the same `%content-type%` you entered to generate the work list. `%group-number%` should be a number to indicate which process group this is. When the run finishes, the number you entered for `%group-number%` will be substituted in the output message after the word 'Group'. Example:

	### Group 3
	* It took 514 seconds to delete 15602 revisions (30 revisions per second).

Now wait ... what's that ampersand doing at the end of the statement I told you to just drop into the shell? That ampersand tells bash to release the shell back to you. Why do that? So you can do something like this:

	$ drush nrc-wl blog 1 &
	$ drush nrc-wl blog 2 &
	$ drush nrc-wl blog 3 &

Catching the drift? Running multiple instances of the script will allow you clean up that much faster. I've had success with up to 2 x (# of cores - 1) on machines hosting the database server on the same machine. So, on my quad core laptop 2 x (4 - 1) = 6. Running six instances of the script allowed the laptop to dedicate about 60% of each utilized core to PHP and left one core for MySQL, which it hogged all of!

As your jobs complete, they will print the number of node revisions they deleted back to the screen. This may be annoying, if you intend on using that terminal window for something else. You can opt to pipe that information to a report file, in stead by running:

	$ echo '' > /path/to/report-file.txt
	$ drush nrc-wl blog 1 >> /path/to/report-file.txt &
	$ drush nrc-wl blog 2 >> /path/to/report-file.txt &
	$ drush nrc-wl blog 3 >> /path/to/report-file.txt &

The double greater than symbol is important, as it tells bash to append to that file, rather than replace its contents. As each process finishes, it will append its results to the file, rather than output them to the screen.

Alternatively, run each process in a reattachable screen or tmux session.

### Step 3 - Monitor.

In that second terminal window I told you to open up (you did, didn't you?), cd or ssh to your Drupal root and type `drush nrc-report %content-type%`, again, entering the content type you generated the job queue for. If you're an enterprising young lad or lass, you've got a system with watch installed. If you do, type `watch -n2 drush nrc-report %content-type%`. That particular switch, `-n2` tells watch to re-run the script every 2 seconds. Adjust as needed.

## Additional Tricks

### Disclaimer

Should you perform any of the actions or utilize any of the information laid out in this section of this README file, you do so at your own risk. The author and maintainers of this module have provided this information as reference only, and it is up to you to do further research and due diligence before implementing any of these ideas.

No, seriously, folks, don't try this stuff unless you actually know what you're doing.

### Not so dangerous zone

#### jobs

List the background processes for the current user.

#### disown

This handy little command, when passed the -h option, will tell the system no to pass the SIGHUP signal to the processes listed in `jobs` when the terminal closes. Although nrc has some built in logic to safely handle SIGHUPs and other signals, it may be a good idea to `disown -h`, just in case.

### __DANGER ZONE__

No, seriously, these are only to be run by pros. In non-production environments. Where angels with safety nets and hand grenades guard your backups.

Remember that time you were told to do a backup? You backed up the server, too, right?

#### nice and renice

Running the work-lists (nrc-wl) command can take a pretty long time, depending on the total number of node revisions you have to delete. Setting the 'niceness' of your process will help the *nix box you're working on understand that your process needs more or fewer resources dedicated to it's execution. Most operating systems operate on niceness levels between -20 and 20, with most processes launching with the default niceness level of 0. A positive nice level will tell the system to dedicate fewer resources, and a negative nice level tells it to dedicate more. In our previous example, the command to launch nrc-wl was:

	$ drush nrc-wl blog 1 >> /path/to/report-file.txt &

To set the nice level at the time of execution to tell the system to dedicate more resources, you might try:

	$ nice -n -10 drush nrc-wl blog 1 >> /path/to/report-file.txt &

If you've already launched the process and notice using top (or another similar utility) that your nrc-wl isn't being taken seriously, note the PID number for the process and renice it, like so (Note: you'll probably have to sudo this command or sudo su and issue it as root; Ubuntu 14.04, for example, only allows renice by root, not under sudo.):

	$ renice -10 -p PID

If you don't know how to find your process' PID, you should not attempt this.

While you can nice and renice to -20, I try to leave that level for core system functionality, opting, instead, for -19.

#### Set the real time scheduling priority

I've experienced some success with setting the scheduling priority to SCHED_FIFO. Rather than repeat the excellent tutorial I follow when adjusting scheduling priorities, I'll just [link](http://www.cyberciti.biz/faq/howto-set-real-time-scheduling-priority-process/) you to it.

#### Set the processor affinity

I should've stopped at the last one. Occasionally, setting a processor affinity (which processor/s the script may run on) has helped. Let's say you have a quad-core processor on the machine you're running `nrc-wl`. You could, theoretically run 6 invocations of the script, assigning 1 and 2 to core 0, 3 and 4 to core 2, and 5 and 6 to core 3. This setup would then leave the fourth core open to process all other system functions. If you've set the niceness and real time scheduling priority properly, you may find that you can max out your CPU usage on each of the 3 cores handling your script. Do I suggest doing this for long periods of time? No. Are you nuts? Have you looked at the price of decent replacement processors recently? What? You rent a VPS or got the go-ahead from IT? Oh. Maybe give it a try. Again, here's a [link to the tutorial](http://www.cyberciti.biz/tips/setting-processor-affinity-certain-task-or-process.html).
